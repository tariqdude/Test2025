import { describe, it, expect, beforeEach, vi } from 'vitest';
import { mkdtempSync, writeFileSync, rmSync } from 'fs';
import path from 'path';
import { PerformanceAnalyzer } from '../analysis/performance';
import { AccessibilityAnalyzer } from '../analysis/accessibility';
import { DeploymentAnalyzer } from '../analysis/deployment';
import { SecurityAnalyzer } from '../analysis/security';
import { GitAnalyzer } from '../analysis/git';
import type { AnalyzerConfig } from '../config/schema';

// Mock file system with proper default export
vi.mock('fs', async () => {
  const actual = await vi.importActual<typeof import('fs')>('fs');
  return {
    ...actual,
    default: actual,
    promises: {
      readFile: vi.fn().mockResolvedValue(''),
      access: vi.fn().mockResolvedValue(undefined),
      stat: vi.fn().mockResolvedValue({ size: 1000 }),
      readdir: vi.fn().mockResolvedValue([]),
    },
  };
});

// Mock glob
vi.mock('glob', () => ({
  glob: vi.fn().mockResolvedValue([]),
}));

// Mock command executor
vi.mock('../utils/command-executor', () => ({
  executeCommand: vi.fn().mockResolvedValue({
    stdout: '',
    stderr: '',
    exitCode: 0,
    signal: null,
  }),
}));

// Mock logger
vi.mock('../utils/logger', () => ({
  logger: {
    debug: vi.fn(),
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
    fatal: vi.fn(),
    setMinLevel: vi.fn(),
  },
}));

describe('Performance Analyzer', () => {
  let analyzer: PerformanceAnalyzer;
  let mockConfig: AnalyzerConfig;

  beforeEach(async () => {
    vi.clearAllMocks();
    const { glob } = await import('glob');
    vi.mocked(glob).mockResolvedValue([]);
    analyzer = new PerformanceAnalyzer();
    mockConfig = {
      projectRoot: '/test/project',
      ignore: ['node_modules'],
      include: ['**/*.{ts,tsx,js,jsx}'],
      frameworks: ['react'],
      enabledAnalyzers: ['performance'],
      severityThreshold: 'low',
      outputFormat: 'terminal',
      githubIntegration: true,
      deploymentChecks: true,
      autoFix: false,
      watchMode: false,
      enableCache: true,
    };
  });

  it('should have correct analyzer name', () => {
    expect(analyzer.name).toBe('PerformanceAnalyzer');
  });

  it('should be enabled when performance is in enabledAnalyzers', () => {
    expect(analyzer.canAnalyze(mockConfig)).toBe(true);
  });

  it('should be disabled when performance is not in enabledAnalyzers', () => {
    const config = { ...mockConfig, enabledAnalyzers: ['syntax'] };
    expect(analyzer.canAnalyze(config)).toBe(false);
  });

  it('should return an array of issues', async () => {
    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });

  it('should handle analysis gracefully on error', async () => {
    const { glob } = await import('glob');
    vi.mocked(glob).mockRejectedValueOnce(new Error('Glob error'));

    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });
});

describe('Accessibility Analyzer', () => {
  let analyzer: AccessibilityAnalyzer;
  let mockConfig: AnalyzerConfig;

  beforeEach(() => {
    vi.clearAllMocks();
    analyzer = new AccessibilityAnalyzer();
    mockConfig = {
      projectRoot: '/test/project',
      ignore: ['node_modules'],
      include: ['**/*.{astro,tsx,jsx}'],
      frameworks: ['astro'],
      enabledAnalyzers: ['accessibility'],
      severityThreshold: 'low',
      outputFormat: 'terminal',
      githubIntegration: true,
      deploymentChecks: true,
      autoFix: false,
      watchMode: false,
      enableCache: true,
    };
  });

  it('should have correct analyzer name', () => {
    expect(analyzer.name).toBe('AccessibilityAnalyzer');
  });

  it('should be enabled when accessibility is in enabledAnalyzers', () => {
    expect(analyzer.canAnalyze(mockConfig)).toBe(true);
  });

  it('should be disabled when accessibility is not in enabledAnalyzers', () => {
    const config = { ...mockConfig, enabledAnalyzers: ['syntax'] };
    expect(analyzer.canAnalyze(config)).toBe(false);
  });

  it('should return an array of issues', async () => {
    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });

  it('should detect missing alt text on images', async () => {
    const actualFs = await vi.importActual<typeof import('fs')>('fs');
    const tmpRoot = mkdtempSync(path.join(process.cwd(), 'a11y-fixture-'));
    const filePath = path.join(tmpRoot, 'page.astro');
    writeFileSync(filePath, '<img src="image.jpg">', 'utf-8');

    // Let analyzer read real fixture content instead of the global fs mock
    vi.mocked((await import('fs')).promises.readFile).mockImplementation(
      actualFs.promises.readFile
    );
    const { glob } = await import('glob');
    vi.mocked(glob).mockResolvedValue([filePath]);

    const config = {
      ...mockConfig,
      projectRoot: tmpRoot,
      ignore: [],
      include: ['**/*.astro'],
    };

    try {
      const issues = await analyzer.analyze(config);
      expect(Array.isArray(issues)).toBe(true);
      expect(
        issues.some(
          issue =>
            issue.rule === 'accessibility-pattern' &&
            issue.description.includes('alt attributes')
        )
      ).toBe(true);
    } finally {
      rmSync(tmpRoot, { recursive: true, force: true });
    }
  });

  it('should handle pattern scanning errors gracefully', async () => {
    const { promises: fs } = await import('fs');
    vi.mocked(fs.readFile).mockRejectedValue(new Error('read failure'));

    const results = await (analyzer as unknown as {
      _checkFileForPatterns: (
        filePath: string,
        patterns: Array<{
          pattern: RegExp;
          message: string;
          severity: 'critical' | 'high' | 'medium' | 'low';
          type: string;
          category: string;
          source: string;
          rule: string;
          suggestion?: string;
          autoFixable: boolean;
        }>,
        projectRoot: string
      ) => Promise<
        Array<{
          rule: string;
          description: string;
        }>
      >;
    })._checkFileForPatterns(
      '/test/project/page.astro',
      [
        {
          pattern: /token/,
          message: 'Found token',
          severity: 'medium',
          type: 'accessibility',
          category: 'Accessibility',
          source: 'a11y-scanner',
          rule: 'accessibility-pattern',
          suggestion: 'Handle token',
          autoFixable: false,
        },
      ],
      mockConfig.projectRoot
    );

    expect(results).toEqual([]);
  });
});

describe('Deployment Analyzer', () => {
  let analyzer: DeploymentAnalyzer;
  let mockConfig: AnalyzerConfig;

  beforeEach(() => {
    vi.clearAllMocks();
    analyzer = new DeploymentAnalyzer();
    mockConfig = {
      projectRoot: '/test/project',
      ignore: ['node_modules'],
      include: ['**/*.{ts,tsx}'],
      frameworks: [],
      enabledAnalyzers: ['deployment'],
      severityThreshold: 'low',
      outputFormat: 'terminal',
      githubIntegration: true,
      deploymentChecks: true,
      autoFix: false,
      watchMode: false,
      enableCache: true,
    };
  });

  it('should have correct analyzer name', () => {
    expect(analyzer.name).toBe('DeploymentAnalyzer');
  });

  it('should be enabled when deployment is in enabledAnalyzers', () => {
    expect(analyzer.canAnalyze(mockConfig)).toBe(true);
  });

  it('should be disabled when deployment is not in enabledAnalyzers', () => {
    const config = { ...mockConfig, enabledAnalyzers: ['syntax'] };
    expect(analyzer.canAnalyze(config)).toBe(false);
  });

  it('should return an array of issues', async () => {
    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });

  it('should handle build during npm lifecycle', async () => {
    // Simulate being in build lifecycle
    const originalEnv = process.env.npm_lifecycle_event;
    process.env.npm_lifecycle_event = 'build';

    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);

    // Restore
    process.env.npm_lifecycle_event = originalEnv;
  });

  it('should skip when deployment checks are disabled', async () => {
    const disabledConfig = { ...mockConfig, deploymentChecks: false };
    expect(analyzer.canAnalyze(disabledConfig)).toBe(false);
    const issues = await analyzer.analyze(disabledConfig);
    expect(issues).toEqual([]);
  });

  it('should expose last checklist metadata', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand).mockResolvedValue({
      stdout: '',
      stderr: '',
      exitCode: 0,
      signal: null,
      duration: 10,
    });

    await analyzer.analyze(mockConfig);
    const meta = analyzer.getLastChecklist();
    expect(meta).toBeDefined();
    expect(meta?.buildStatus).toBeDefined();
  });
});

describe('Git Analyzer', () => {
  let analyzer: GitAnalyzer;
  let mockConfig: AnalyzerConfig;

  beforeEach(() => {
    vi.clearAllMocks();
    analyzer = new GitAnalyzer();
    mockConfig = {
      projectRoot: '/test/project',
      ignore: [],
      include: [],
      frameworks: [],
      enabledAnalyzers: ['git'],
      severityThreshold: 'low',
      outputFormat: 'terminal',
      githubIntegration: true,
      deploymentChecks: true,
      autoFix: false,
      watchMode: false,
      enableCache: true,
    };
  });

  it('should have correct analyzer name', () => {
    expect(analyzer.name).toBe('GitAnalyzer');
  });

  it('should be enabled when git is in enabledAnalyzers', () => {
    expect(analyzer.canAnalyze(mockConfig)).toBe(true);
  });

  it('should be disabled when git is not in enabledAnalyzers', () => {
    const config = { ...mockConfig, enabledAnalyzers: ['syntax'] };
    expect(analyzer.canAnalyze(config)).toBe(false);
  });

  it('should return an array of issues', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand)
      .mockResolvedValueOnce({
        stdout: 'main',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: 'abc123 Latest commit',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '0\t0',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      });

    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });

  it('should detect uncommitted changes', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand)
      .mockResolvedValueOnce({
        stdout: 'main',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: 'M src/file.ts\nA src/new.ts',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: 'abc123 Latest commit',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '1\t0',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      });

    const issues = await analyzer.analyze(mockConfig);
    const uncommittedIssue = issues.find(i => i.title.includes('Uncommitted'));
    expect(uncommittedIssue).toBeDefined();
  });

  it('should capture upstream branch misalignment', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand)
      .mockResolvedValueOnce({
        stdout: 'main',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: 'abc123 Latest commit',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '0\t2',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      });

    const issues = await analyzer.analyze(mockConfig);
    expect(
      issues.some(issue => issue.rule === 'git-branch-alignment')
    ).toBe(true);
    expect(analyzer.getLastAnalysis()?.branchStatus).toBe('behind');
    expect(analyzer.getLastAnalysis()?.behindBy).toBe(2);
  });

  it('should handle git command errors gracefully', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand).mockRejectedValueOnce(
      new Error('Not a git repository')
    );

    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });

  it('should expose last analysis metadata', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand)
      .mockResolvedValueOnce({
        stdout: 'main',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: 'abc123 Latest commit',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      })
      .mockResolvedValueOnce({
        stdout: '0\t0',
        stderr: '',
        exitCode: 0,
        signal: null,
        duration: 10,
      });

    await analyzer.analyze(mockConfig);
    const meta = analyzer.getLastAnalysis();
    expect(meta).toBeDefined();
    expect(meta?.branch).toBe('main');
    expect(meta?.commit).toBe('abc123');
  });
});

describe('Performance Analyzer (environment gating)', () => {
  let analyzer: PerformanceAnalyzer;
  let mockConfig: AnalyzerConfig;

  beforeEach(() => {
    vi.clearAllMocks();
    analyzer = new PerformanceAnalyzer();
    mockConfig = {
      projectRoot: '/test/project',
      ignore: ['node_modules'],
      include: ['**/*.{ts,tsx,js,jsx}'],
      frameworks: ['react'],
      enabledAnalyzers: ['performance'],
      severityThreshold: 'low',
      outputFormat: 'terminal',
      githubIntegration: true,
      deploymentChecks: true,
      autoFix: false,
      watchMode: false,
      enableCache: true,
    };
  });

  it('should skip heavy bundle check in CI', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    const originalCI = process.env.CI;
    process.env.CI = 'true';

    await analyzer.analyze(mockConfig);
    expect(vi.mocked(executeCommand)).not.toHaveBeenCalled();

    process.env.CI = originalCI;
  });

  it('should avoid bundle analysis when watch mode is enabled', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    const watchConfig = { ...mockConfig, watchMode: true };

    await analyzer.analyze(watchConfig);
    expect(vi.mocked(executeCommand)).not.toHaveBeenCalled();
  });
});

describe('Security Analyzer', () => {
  let analyzer: SecurityAnalyzer;
  let mockConfig: AnalyzerConfig;

  beforeEach(() => {
    vi.clearAllMocks();
    analyzer = new SecurityAnalyzer();
    mockConfig = {
      projectRoot: '/test/project',
      ignore: ['node_modules'],
      include: ['**/*.{ts,tsx,js,jsx}'],
      frameworks: ['react'],
      enabledAnalyzers: ['security'],
      severityThreshold: 'low',
      outputFormat: 'terminal',
      githubIntegration: true,
      deploymentChecks: true,
      autoFix: false,
      watchMode: false,
      enableCache: true,
    };
  });

  it('handles npm audit errors gracefully', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand).mockRejectedValueOnce(
      new Error('network offline')
    );

    const issues = await analyzer.analyze(mockConfig);
    expect(Array.isArray(issues)).toBe(true);
  });

  it('parses npm audit output respecting severity threshold', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand).mockResolvedValueOnce({
      stdout: JSON.stringify({
        metadata: { vulnerabilities: { critical: 1, high: 1, moderate: 2 } },
      }),
      stderr: '',
      exitCode: 0,
      signal: null,
    });

    const strictConfig = { ...mockConfig, severityThreshold: 'high' };
    const issues = await analyzer.analyze(strictConfig);
    // Debug output to verify parsed issues
    // eslint-disable-next-line no-console
    console.log('audit issues (high threshold):', issues);
    expect(issues.some(i => i.severity.level === 'high')).toBe(true);
    expect(issues.some(i => i.severity.level === 'critical')).toBe(true);
    expect(issues.some(i => i.severity.level === 'medium')).toBe(false);
  });

  it('honors medium threshold for npm audit output with low severity vulns', async () => {
    const { executeCommand } = await import('../utils/command-executor');
    vi.mocked(executeCommand).mockResolvedValueOnce({
      stdout: JSON.stringify({
        metadata: { vulnerabilities: { moderate: 1, low: 2 } },
      }),
      stderr: '',
      exitCode: 0,
      signal: null,
    });

    const issues = await analyzer.analyze({
      ...mockConfig,
      severityThreshold: 'medium',
    });

    expect(issues.some(i => i.severity.level === 'medium')).toBe(true);
    expect(issues.some(i => i.severity.level === 'low')).toBe(false);
  });

  it('flags committed environment files', async () => {
    const tmpRoot = mkdtempSync(path.join(process.cwd(), 'env-fixture-'));
    const envPath = path.join(tmpRoot, '.env.local');
    writeFileSync(envPath, 'SECRET_KEY=should-not-commit', 'utf-8');

    const { glob } = await import('glob');
    vi.mocked(glob)
      .mockResolvedValueOnce([]) // security patterns
      .mockResolvedValueOnce([]) // environment content scanning
      .mockResolvedValueOnce([envPath]); // env file detection

    try {
      const issues = await analyzer.analyze({
        ...mockConfig,
        projectRoot: tmpRoot,
        ignore: [],
        include: ['**/*'],
      });

      expect(
        issues.some(issue => issue.rule === 'env-files-in-repo')
      ).toBe(true);
    } finally {
      rmSync(tmpRoot, { recursive: true, force: true });
    }
  });
});
